{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "e3030c34-c1f8-4e69-879b-ef7748450f3d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "b1d8ac7a-d223-48de-c479-3f7a93ff4b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "Setup complete âœ… (20 CPUs, 62.5 GB RAM, 200.9/227.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in ./seg-14 to yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33987/33987 [00:03<00:00, 11103.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ./seg-14 in yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1662/1662 [00:00<00:00, 13175.77it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"T3E2M8jPKMaklrg9Ouoq\")\n",
        "project = rf.workspace(\"runaway\").project(\"cats-bfpvf\")\n",
        "version = project.version(14)\n",
        "dataset = version.download(\"yolov8-obb\", location=\"./seg-14\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in ./delete to yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25109/25109 [00:02<00:00, 11503.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ./delete in yolov8-obb:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1264/1264 [00:00<00:00, 10344.34it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"T3E2M8jPKMaklrg9Ouoq\")\n",
        "project = rf.workspace(\"runaway\").project(\"cats-bfpvf\")\n",
        "version = project.version(13)\n",
        "dataset = version.download(\"yolov8-obb\", location=\"./delete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"T3E2M8jPKMaklrg9Ouoq\")\n",
        "project = rf.workspace(\"runaway\").project(\"cats-bfpvf\")\n",
        "version = project.version(13)\n",
        "dataset = version.download(\"coco\", location=\"./coco-bounding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics.data.converter import convert_coco\n",
        "\n",
        "convert_coco(labels_dir=\"./coco-bounding/train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"T3E2M8jPKMaklrg9Ouoq\")\n",
        "project = rf.workspace(\"runaway\").project(\"cats-bfpvf\")\n",
        "version = project.version(13)\n",
        "dataset = version.download(\"yolov8\", location=\"./bounding-box\")\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "9443d83d-d116-437f-845b-2cef876bf9db"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/roboflow_datasets\n",
        "%cd {HOME}/roboflow_datasets\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"T3E2M8jPKMaklrg9Ouoq\")\n",
        "project = rf.workspace(\"runaway\").project(\"cats-bfpvf\")\n",
        "version = project.version(13)\n",
        "dataset = version.download(\"yolov8-obb\")\n",
        "                "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "b9c28885-60eb-4fe4-f94e-63ec59ad2be1"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=segment mode=train model=yolov8s-seg.pt data={dataset.location}/data.yaml epochs=200 imgsz=500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!yolo task=segment mode=train model=yolov8s-seg.pt data=./cropped_roboflow5-224/data.yaml epochs=400 imgsz=224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "70e28b87-1d0f-4c77-eaee-0621de1b34b9"
      },
      "outputs": [],
      "source": [
        "!ls runs/segment/train32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_J35i8Ofhjxa",
        "outputId": "d89a5193-1e58-4be9-bc6a-e3e5945202c1"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'runs/segment/train32/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/segment/train35/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "HI4nADCCj3F5",
        "outputId": "9307790f-c41f-49a1-b5fd-5980c5199d9a"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/segment/train23/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bounding-box\t\t runaway-seg-11\n",
            "bounding_box_224\t runs\n",
            "cats-13\t\t\t SampleSubmission.csv\n",
            "coco-bounding\t\t seg-converted-bb\n",
            "coco_converted\t\t seg-converted-bb-full-augmentation\n",
            "coco_converted_224\t seg-data\n",
            "cropped_roboflow\t seg-data2\n",
            "cropped_roboflow-12-200  separated_locations_224\n",
            "cropped_roboflow2\t submission.csv\n",
            "cropped_roboflow-256\t test-data-masked\n",
            "cropped_roboflow3-224\t test_images\n",
            "cropped_roboflow4-224\t test.png\n",
            "cropped_roboflow5-224\t venv\n",
            "datasets\t\t yolov10x.pt\n",
            "imaug\t\t\t yolov8n.pt\n",
            "results\t\t\t yolov8s-seg.pt\n",
            "roboflow_datasets\t yolov8x.pt\n",
            "runaway-seg-10\t\t yolov8x-seg.pt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpyuwrNlXc1P",
        "outputId": "be5030a3-7431-4c5d-9e6b-9a3b90793f44"
      },
      "outputs": [],
      "source": [
        "!yolo task=segment mode=val model=./runs/segment/train22/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train23/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train24/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train25/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train29/weights/best.pt data=./cropped_roboflow2/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow2/valid/labels.cache... \u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         55         55      0.997      0.945      0.987      0.847      0.937      0.927      0.931      0.603\n",
            "Speed: 1.1ms preprocess, 7.2ms inference, 0.0ms loss, 7.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val8\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow2/valid/labels.cache... \u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         55         55      0.935      0.855      0.907      0.738      0.913      0.836      0.887      0.499\n",
            "Speed: 0.8ms preprocess, 8.2ms inference, 0.0ms loss, 5.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val9\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow5-224/valid/labels.cache\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         93         67       0.92      0.896      0.941       0.69      0.904      0.821       0.87      0.433\n",
            "Speed: 0.4ms preprocess, 2.1ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val10\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow5-224/valid/labels.cache\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         93         67      0.901      0.819      0.887      0.682      0.885      0.804      0.853      0.449\n",
            "Speed: 0.3ms preprocess, 2.9ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val11\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv10x summary (fused): 503 layers, 31,586,006 parameters, 0 gradients, 169.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow2/valid/labels.cache... \u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         55         55      0.932      0.818      0.913      0.579\n",
            "Speed: 1.0ms preprocess, 10.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv10x summary (fused): 503 layers, 31,586,006 parameters, 0 gradients, 169.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/cropped_roboflow5-224/valid/labels.cache\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all         93         67      0.819      0.742        0.8       0.52\n",
            "Speed: 0.7ms preprocess, 7.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=segment mode=val model=./runs/segment/train35/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train36/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train35/weights/best.pt data=./cropped_roboflow5-224/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train36/weights/best.pt data=./cropped_roboflow5-224/data.yaml\n",
        "!yolo detect val model=./runs/detect/train20/weights/best.pt data=./cropped_roboflow2/data.yaml\n",
        "!yolo detect val model=./runs/detect/train20/weights/best.pt data=./cropped_roboflow5-224/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/seg-converted-bb-full-augmentation/valid\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/p.kuznetsov/runaway/venv/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/cfg/__init__.py\", line 830, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/engine/model.py\", line 648, in val\n",
            "    validator(model=self.model)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/engine/validator.py\", line 187, in __call__\n",
            "    self.update_metrics(preds, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/segment/val.py\", line 110, in update_metrics\n",
            "    pbatch = self._prepare_batch(si, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/segment/val.py\", line 88, in _prepare_batch\n",
            "    prepared_batch = super()._prepare_batch(si, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/detect/val.py\", line 107, in _prepare_batch\n",
            "    cls = batch[\"cls\"][idx].squeeze(-1)\n",
            "IndexError: The shape of the mask [15] at index 0 does not match the shape of the indexed tensor [0, 1] at index 0\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/seg-converted-bb-full-augmentation/valid\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/p.kuznetsov/runaway/venv/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/cfg/__init__.py\", line 830, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/engine/model.py\", line 648, in val\n",
            "    validator(model=self.model)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/engine/validator.py\", line 187, in __call__\n",
            "    self.update_metrics(preds, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/segment/val.py\", line 110, in update_metrics\n",
            "    pbatch = self._prepare_batch(si, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/segment/val.py\", line 88, in _prepare_batch\n",
            "    prepared_batch = super()._prepare_batch(si, batch)\n",
            "  File \"/home/p.kuznetsov/runaway/venv/lib/python3.9/site-packages/ultralytics/models/yolo/detect/val.py\", line 107, in _prepare_batch\n",
            "    cls = batch[\"cls\"][idx].squeeze(-1)\n",
            "IndexError: The shape of the mask [15] at index 0 does not match the shape of the indexed tensor [0, 1] at index 0\n",
            "Ultralytics YOLOv8.2.94 ðŸš€ Python-3.9.7 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11012MiB)\n",
            "YOLOv10x summary (fused): 503 layers, 31,586,006 parameters, 0 gradients, 169.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/p.kuznetsov/runaway/seg-converted-bb-full-augmentation/valid\u001b[0m\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
            "                   all        132        112       0.64      0.438        0.5      0.277\n",
            "Speed: 0.4ms preprocess, 7.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=segment mode=val model=./runs/segment/train35/weights/best.pt data=./seg-converted-bb-full-augmentation/data.yaml\n",
        "!yolo task=segment mode=val model=./runs/segment/train36/weights/best.pt data=./seg-converted-bb-full-augmentation/data.yaml\n",
        "!yolo detect val model=./runs/detect/train20/weights/best.pt data=./seg-converted-bb-full-augmentation/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jbVjEtPAkz3j",
        "outputId": "57e15b61-efd4-4877-ff08-413ed92d004f"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(f'{HOME}/runs/segment/predict2/*.jpg')[:3]:\n",
        "      display(Image(filename=image_path, height=600))\n",
        "      print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save & Deploy model\n",
        "\n",
        "Once you have finished training your YOLOv8 model, youâ€™ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload and your model weights to Roboflow Deploy for autolabeling, autoscaling inference, and using later.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) supports uploading YOLOv8 weights.\n",
        "\n",
        "Run this cell to save your model weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dependency ultralytics==8.0.196 is required but found version=8.2.94, to fix: `pip install ultralytics==8.0.196`\n",
            "View the status of your deployment at: https://app.roboflow.com/runaway/cats-bfpvf/13\n",
            "Share your model with the world at: https://universe.roboflow.com/runaway/cats-bfpvf/model/13\n"
          ]
        }
      ],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov8-seg\", model_path=f\"./runs/segment/train37/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
